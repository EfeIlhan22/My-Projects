{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1CiwAhrgz-uciqIy1o2G9bzM6XWYHIFwt",
      "authorship_tag": "ABX9TyNHX4PXQGq+gzUbEVEbZ82O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EfeIlhan22/My-Projects/blob/NLP/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bölüm 1: Verilerin Yüklenmesi ve Hazırlanması\n",
        "import os\n",
        "!pip install datasets\n",
        "!pip install transformers scikit-learn torch pandas tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ziGKWOqHyW9i",
        "outputId": "fe02c17c-981b-4fb6-fe3b-f9abf73919cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.61)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWR3A2lby7OW",
        "outputId": "2d9fb532-198c-4d18-c1d9-50b0bad3ffb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verilerin Yüklenmesi\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Ana klasör yolu\n",
        "main_dir = \"/content/drive/MyDrive/makaleler-yazarlar\"\n",
        "\n",
        "# Her label için dosyaları gez\n",
        "for label, folder in enumerate(os.listdir(main_dir)):\n",
        "    folder_path = os.path.join(main_dir, folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        for txt_file in os.listdir(folder_path):\n",
        "            if txt_file.endswith(\".txt\"):\n",
        "                file_path = os.path.join(folder_path, txt_file)\n",
        "                with open(file_path, 'r', encoding='ISO-8859-9') as file:\n",
        "                    text = file.read().strip()\n",
        "                    data.append(text)\n",
        "                    labels.append(label)\n",
        "\n",
        "# Verileri DataFrame'e dönüştür\n",
        "df = pd.DataFrame({\"text\": data, \"label\": labels})\n"
      ],
      "metadata": {
        "id": "r61sDA7uyXZ7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
        "        }"
      ],
      "metadata": {
        "id": "xsRHZ8GNE9-M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bölüm 2: Stratified K-Fold Cross-Validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# BERTürk Tokenizer ve Model\n",
        "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Bölüm 3: Eğitim ve Değerlendirme Fonksiyonları\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# GPU kullanımı kontrolü\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "results = []"
      ],
      "metadata": {
        "id": "SOLvfpTQycNB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "def train(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, device, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Detaylı metrik raporu\n",
        "    report = classification_report(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        target_names=class_names,\n",
        "        output_dict=True,\n",
        "        zero_division=0  # Sıfır bölme hatasını önle\n",
        "    )\n",
        "\n",
        "    # DataFrame'e dönüştürme\n",
        "    df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "    # İstenen formatta tablo oluşturma\n",
        "    performance_df = pd.DataFrame(columns=[\"Class 1\", \"Class 2\", \"...\", \"Class 29\", \"Class 30\", \"Average\"])\n",
        "\n",
        "    # Her sınıf için değerleri doldurma\n",
        "    for i in range(len(class_names)):\n",
        "        class_name = f\"Class {i+1}\"\n",
        "        performance_df.loc[\"Precision\", class_name] = df_report.loc[class_name, \"precision\"]\n",
        "        performance_df.loc[\"Recall\", class_name] = df_report.loc[class_name, \"recall\"]\n",
        "        performance_df.loc[\"F-Score\", class_name] = df_report.loc[class_name, \"f1-score\"]\n",
        "\n",
        "    # Ortalama değerleri ekleme\n",
        "    performance_df[\"Average\"] = [\n",
        "        df_report.loc[\"macro avg\", \"precision\"],\n",
        "        df_report.loc[\"macro avg\", \"recall\"],\n",
        "        df_report.loc[\"macro avg\", \"f1-score\"]\n",
        "    ]\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return performance_df.round(4), accuracy  # İki değer döndür"
      ],
      "metadata": {
        "id": "LmDBScoJAlrX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Parametreler\n",
        "    BATCH_SIZE = 16\n",
        "    EPOCHS = 10\n",
        "    MAX_LENGTH = 128\n",
        "    LR = 5e-5\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    fold_accuracies = []\n",
        "\n",
        "    texts = df[\"text\"].tolist()\n",
        "    labels = df[\"label\"].tolist()\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels)):\n",
        "        print(f\"\\nFold {fold + 1}\")\n",
        "\n",
        "        # Verileri ayırma\n",
        "        train_texts = [texts[i] for i in train_idx]\n",
        "        train_labels = [labels[i] for i in train_idx]\n",
        "        val_texts = [texts[i] for i in val_idx]\n",
        "        val_labels = [labels[i] for i in val_idx]\n",
        "\n",
        "        train_dataset = TextDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n",
        "        val_dataset = TextDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "        # Model ve optimizer tanımlama\n",
        "        model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(set(labels)))\n",
        "        model.to(DEVICE)\n",
        "        optimizer = AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "        # Eğitim döngüsü\n",
        "        for epoch in range(EPOCHS):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "            train_loss = train(model, train_loader, optimizer, DEVICE)\n",
        "            print(f\"Training Loss: {train_loss}\")\n",
        "\n",
        "        class_names = [f\"Class {i+1}\" for i in range(len(set(labels)))]\n",
        "\n",
        "        # Değerlendirme\n",
        "        performance_df, accuracy = evaluate(model, val_loader, DEVICE, class_names)\n",
        "        print(f\"Fold {fold + 1} Accuracy: {accuracy}\")\n",
        "        print(f\"\\\\nFold {fold + 1} Performance Report:\")\n",
        "        print(performance_df.to_markdown())\n",
        "        fold_accuracies.append(accuracy)\n",
        "\n",
        "    # Sonuçlar\n",
        "    print(f\"\\nAverage Accuracy: {sum(fold_accuracies) / len(fold_accuracies)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nugBa_u3FbXS",
        "outputId": "de09a605-6c50-48b1-99e9-03954d9aa38c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 3.1624766540527345\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  2.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.8925074593226114\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0096226676305136\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.44735352536042533\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.17448540012041727\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.08575300777951876\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.07459539656837781\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.03265005134046078\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.023335045178731282\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.0208489145586888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 19/19 [00:05<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Accuracy: 0.8433333333333334\n",
            "\\nFold 1 Performance Report:\n",
            "|           |   Class 1 |   Class 2 |   ... |   Class 29 |   Class 30 |   Average |   Class 3 |   Class 4 |   Class 5 |   Class 6 |   Class 7 |   Class 8 |   Class 9 |   Class 10 |   Class 11 |   Class 12 |   Class 13 |   Class 14 |   Class 15 |   Class 16 |   Class 17 |   Class 18 |   Class 19 |   Class 20 |   Class 21 |   Class 22 |   Class 23 |   Class 24 |   Class 25 |   Class 26 |   Class 27 |   Class 28 |\n",
            "|:----------|----------:|----------:|------:|-----------:|-----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|\n",
            "| Precision |  0.818182 |       0.6 |   nan |          1 |   0.75     |    0.855  |    0.6667 |    0.7273 |    1      |    0.9091 |    0.7778 |         1 |         1 |          1 |     0.9091 |     0.875  |     0.8571 |     1      |     0.4667 |     0.8889 |     0.8889 |     0.7143 |          1 |          1 |     0.7778 |     0.5714 |        0.8 |     0.875  |          1 |     0.7778 |          1 |          1 |\n",
            "| Recall    |  0.9      |       0.6 |   nan |          1 |   0.6      |    0.8433 |    0.6    |    0.8    |    0.9    |    1      |    0.7    |         1 |         1 |          1 |     1      |     0.7    |     0.6    |     0.9    |     0.7    |     0.8    |     0.8    |     1      |          1 |          1 |     0.7    |     0.8    |        0.8 |     0.7    |          1 |     0.7    |          1 |          1 |\n",
            "| F-Score   |  0.857143 |       0.6 |   nan |          1 |   0.666667 |    0.8444 |    0.6316 |    0.7619 |    0.9474 |    0.9524 |    0.7368 |         1 |         1 |          1 |     0.9524 |     0.7778 |     0.7059 |     0.9474 |     0.56   |     0.8421 |     0.8421 |     0.8333 |          1 |          1 |     0.7368 |     0.6667 |        0.8 |     0.7778 |          1 |     0.7368 |          1 |          1 |\n",
            "\n",
            "Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.918170134226481\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.5027977959314982\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.677611571153005\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.2662425084908803\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.12044364030162494\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.05789564847946167\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.03308805048465729\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.024071048175295193\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.01924826775987943\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.015859468368192513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 19/19 [00:04<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Accuracy: 0.8466666666666667\n",
            "\\nFold 2 Performance Report:\n",
            "|           |   Class 1 |   Class 2 |   ... |   Class 29 |   Class 30 |   Average |   Class 3 |   Class 4 |   Class 5 |   Class 6 |   Class 7 |   Class 8 |   Class 9 |   Class 10 |   Class 11 |   Class 12 |   Class 13 |   Class 14 |   Class 15 |   Class 16 |   Class 17 |   Class 18 |   Class 19 |   Class 20 |   Class 21 |   Class 22 |   Class 23 |   Class 24 |   Class 25 |   Class 26 |   Class 27 |   Class 28 |\n",
            "|:----------|----------:|----------:|------:|-----------:|-----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|\n",
            "| Precision |  0.833333 |  0.857143 |   nan |   0.769231 |        0.7 |    0.8594 |    0.75   |    1      |    0.8182 |    1      |    0.75   |         1 |    0.9091 |     1      |          1 |     0.6667 |     1      |          1 |     0.7692 |     0.5625 |     0.4    |     0.7143 |     1      |          1 |       1    |     0.7273 |     0.6667 |     0.8889 |          1 |     1      |          1 |          1 |\n",
            "| Recall    |  1        |  0.6      |   nan |   1        |        0.7 |    0.8467 |    0.9    |    0.8    |    0.9    |    0.8    |    0.6    |         1 |    1      |     0.7    |          1 |     0.8    |     0.7    |          1 |     1      |     0.9    |     0.2    |     1      |     0.9    |          1 |       0.6  |     0.8    |     0.8    |     0.8    |          1 |     0.9    |          1 |          1 |\n",
            "| F-Score   |  0.909091 |  0.705882 |   nan |   0.869565 |        0.7 |    0.8423 |    0.8182 |    0.8889 |    0.8571 |    0.8889 |    0.6667 |         1 |    0.9524 |     0.8235 |          1 |     0.7273 |     0.8235 |          1 |     0.8696 |     0.6923 |     0.2667 |     0.8333 |     0.9474 |          1 |       0.75 |     0.7619 |     0.7273 |     0.8421 |          1 |     0.9474 |          1 |          1 |\n",
            "\n",
            "Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 3.2052367369333905\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.7871306864420573\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8029444003105164\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.32992253283659617\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.16548511882623038\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.08718067198991776\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.03858494537572066\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.025712057625253994\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.02055179428309202\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.016844436054428417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 19/19 [00:04<00:00,  4.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Accuracy: 0.85\n",
            "\\nFold 3 Performance Report:\n",
            "|           |   Class 1 |   Class 2 |   ... |   Class 29 |   Class 30 |   Average |   Class 3 |   Class 4 |   Class 5 |   Class 6 |   Class 7 |   Class 8 |   Class 9 |   Class 10 |   Class 11 |   Class 12 |   Class 13 |   Class 14 |   Class 15 |   Class 16 |   Class 17 |   Class 18 |   Class 19 |   Class 20 |   Class 21 |   Class 22 |   Class 23 |   Class 24 |   Class 25 |   Class 26 |   Class 27 |   Class 28 |\n",
            "|:----------|----------:|----------:|------:|-----------:|-----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|\n",
            "| Precision |  0.692308 |  0.571429 |   nan |   0.75     |        0.7 |    0.8629 |       0.7 |    0.8182 |    0.8333 |    1      |       0.8 |    0.9091 |    0.8333 |     1      |     0.8889 |     0.8571 |     0.8889 |     0.9091 |     0.8182 |     1      |     1      |        0.9 |     0.7778 |          1 |     0.75   |        0.7 |        0.9 |     1      |          1 |     0.8889 |          1 |          1 |\n",
            "| Recall    |  0.9      |  0.8      |   nan |   0.9      |        0.7 |    0.85   |       0.7 |    0.9    |    1      |    0.9    |       0.8 |    1      |    1      |     0.7    |     0.8    |     0.6    |     0.8    |     1      |     0.9    |     0.7    |     0.8    |        0.9 |     0.7    |          1 |     0.9    |        0.7 |        0.9 |     0.7    |          1 |     0.8    |          1 |          1 |\n",
            "| F-Score   |  0.782609 |  0.666667 |   nan |   0.818182 |        0.7 |    0.85   |       0.7 |    0.8571 |    0.9091 |    0.9474 |       0.8 |    0.9524 |    0.9091 |     0.8235 |     0.8421 |     0.7059 |     0.8421 |     0.9524 |     0.8571 |     0.8235 |     0.8889 |        0.9 |     0.7368 |          1 |     0.8182 |        0.7 |        0.9 |     0.8235 |          1 |     0.8421 |          1 |          1 |\n",
            "\n",
            "Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 3.0893622493743895\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.6629571032524109\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.8591389807065328\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.37683771232763924\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.16665976077318193\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.10316832462946574\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.050289692531029384\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.030771365885933242\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.02225400355954965\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.018091195411980152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 19/19 [00:04<00:00,  4.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Accuracy: 0.86\n",
            "\\nFold 4 Performance Report:\n",
            "|           |   Class 1 |   Class 2 |   ... |   Class 29 |   Class 30 |   Average |   Class 3 |   Class 4 |   Class 5 |   Class 6 |   Class 7 |   Class 8 |   Class 9 |   Class 10 |   Class 11 |   Class 12 |   Class 13 |   Class 14 |   Class 15 |   Class 16 |   Class 17 |   Class 18 |   Class 19 |   Class 20 |   Class 21 |   Class 22 |   Class 23 |   Class 24 |   Class 25 |   Class 26 |   Class 27 |   Class 28 |\n",
            "|:----------|----------:|----------:|------:|-----------:|-----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|\n",
            "| Precision |         1 |  0.666667 |   nan |   0.615385 |       1    |    0.8698 |    0.7143 |    0.7778 |         1 |    1      |    0.3636 |    0.9091 |    0.9091 |     0.8571 |     1      |        0.7 |     0.875  |     1      |     1      |     1      |     0.8333 |     0.8333 |     0.8182 |          1 |     0.8333 |     0.6667 |          1 |          1 |          1 |     0.8889 |          1 |     0.8333 |\n",
            "| Recall    |         1 |  0.8      |   nan |   0.8      |       0.6  |    0.86   |    1      |    0.7    |         1 |    0.8    |    0.4    |    1      |    1      |     0.6    |     0.9    |        0.7 |     0.7    |     0.9    |     0.9    |     0.9    |     1      |     1      |     0.9    |          1 |     1      |     0.4    |          1 |          1 |          1 |     0.8    |          1 |     1      |\n",
            "| F-Score   |         1 |  0.727273 |   nan |   0.695652 |       0.75 |    0.8575 |    0.8333 |    0.7368 |         1 |    0.8889 |    0.381  |    0.9524 |    0.9524 |     0.7059 |     0.9474 |        0.7 |     0.7778 |     0.9474 |     0.9474 |     0.9474 |     0.9091 |     0.9091 |     0.8571 |          1 |     0.9091 |     0.5    |          1 |          1 |          1 |     0.8421 |          1 |     0.9091 |\n",
            "\n",
            "Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 3.39869966506958\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 2.202005575497945\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 1.0678974016507468\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.47772255261739094\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:37<00:00,  1.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.23019403596719107\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.09537855063875517\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.051612428824106854\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.07348038929204147\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.02662101442615191\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 75/75 [00:38<00:00,  1.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.019606179719169933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 19/19 [00:05<00:00,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Accuracy: 0.8733333333333333\n",
            "\\nFold 5 Performance Report:\n",
            "|           |   Class 1 |   Class 2 |   ... |   Class 29 |   Class 30 |   Average |   Class 3 |   Class 4 |   Class 5 |   Class 6 |   Class 7 |   Class 8 |   Class 9 |   Class 10 |   Class 11 |   Class 12 |   Class 13 |   Class 14 |   Class 15 |   Class 16 |   Class 17 |   Class 18 |   Class 19 |   Class 20 |   Class 21 |   Class 22 |   Class 23 |   Class 24 |   Class 25 |   Class 26 |   Class 27 |   Class 28 |\n",
            "|:----------|----------:|----------:|------:|-----------:|-----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|-----------:|\n",
            "| Precision |  0.888889 |  0.727273 |   nan |          1 |   0.888889 |    0.8806 |    0.6429 |         1 |    0.8333 |    1      |    0.7273 |    0.9091 |         1 |     0.9091 |     1      |        0.6 |       1    |          1 |        0.8 |     0.8182 |     0.7778 |     0.9091 |        0.9 |          1 |     0.7273 |     0.8    |     0.7692 |        0.9 |          1 |     0.8889 |          1 |          1 |\n",
            "| Recall    |  0.8      |  0.8      |   nan |          1 |   0.8      |    0.8733 |    0.9    |         1 |    1      |    0.9    |    0.8    |    1      |         1 |     1      |     0.8    |        0.6 |       0.6  |          1 |        0.8 |     0.9    |     0.7    |     1      |        0.9 |          1 |     0.8    |     0.4    |     1      |        0.9 |          1 |     0.8    |          1 |          1 |\n",
            "| F-Score   |  0.842105 |  0.761905 |   nan |          1 |   0.842105 |    0.8704 |    0.75   |         1 |    0.9091 |    0.9474 |    0.7619 |    0.9524 |         1 |     0.9524 |     0.8889 |        0.6 |       0.75 |          1 |        0.8 |     0.8571 |     0.7368 |     0.9524 |        0.9 |          1 |     0.7619 |     0.5333 |     0.8696 |        0.9 |          1 |     0.8421 |          1 |          1 |\n",
            "\n",
            "Average Accuracy: 0.8546666666666667\n"
          ]
        }
      ]
    }
  ]
}